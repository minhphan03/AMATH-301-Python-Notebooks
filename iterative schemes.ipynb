{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Week4_2_python.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCn8S50FFh0x"
      },
      "source": [
        "# Week 4 Lecture 2:  Iterative Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyCqFyqgFV5U"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.linalg as la"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb6Yn2NhODFn"
      },
      "source": [
        "# Rahman notes:\n",
        "## Matrix iteration\n",
        "\n",
        "Suppose we have the matrix equation $Ax = b$ where we write $A = I - M$.  As we showed in the theory lecture, we can write a recurrence relation for the solution: $x_{n+1} = Mx_n + b$.  Further assume that this recurrence relation covnerges -- we can test for convergence by verifying the maximal eigenvalue is within unity in absolute value.  Then as $n \\rightarrow \\infty$, $x_n \\rightarrow x$.  Let's see how this works in an example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox8xQdkZsAPt",
        "outputId": "92c012c2-82df-4c7f-d03e-4260a2ec4c4a"
      },
      "source": [
        "### Initialization block\n",
        "n = 10\n",
        "A = np.identity(n) - 0.3*(np.random.rand(n,n) - 0.5)\n",
        "M = np.identity(n)-A\n",
        "b = np.random.rand(n,1)\n",
        "x = np.zeros((n,1))\n",
        "\n",
        "w, V = np.linalg.eig(M)\n",
        "print(np.max(np.abs(w)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.28222311786910625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEkvFkUowmDv",
        "outputId": "faf8cdc2-15a7-4864-8880-d2d738758a97"
      },
      "source": [
        "### Solution block\n",
        "x = M@x + b\n",
        "print('x = ', x, '   Error = ', A@x-b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  [[ 1.080302  ]\n",
            " [ 0.46743161]\n",
            " [ 1.1878141 ]\n",
            " [ 0.48813548]\n",
            " [-0.23018791]\n",
            " [ 0.63394903]\n",
            " [ 0.98852123]\n",
            " [ 0.90072341]\n",
            " [ 1.09857257]\n",
            " [ 1.03717597]]    Error =  [[ 2.10399865e-04]\n",
            " [ 2.70746356e-04]\n",
            " [ 5.97098309e-06]\n",
            " [-1.00354006e-04]\n",
            " [-1.07784711e-03]\n",
            " [-2.00740207e-03]\n",
            " [ 1.44160235e-03]\n",
            " [ 8.02208220e-04]\n",
            " [ 3.53955221e-05]\n",
            " [-4.98039617e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epHa5tk9xLEP"
      },
      "source": [
        "We can just play the solution block to get to the next iterate.  To reset it play the initalization block again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPHa9j7fxr-M"
      },
      "source": [
        "## Jacobi Method\n",
        "\n",
        "A \"good\" algorithm should be robust and fast.  Jacobi's algorithm is based around the more robust additive decomposition of a matrix: $A = L + D + U$.  As we showed in the theory lecture, this gives us the recurrence relation: $x_{n+1} = -D^{-1}(L+U)x_n + D^{-1}b$.  Lets see how this works through the following example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mkZb3_0yGEU"
      },
      "source": [
        "### Initialization Block\n",
        "d = np.array([1, 2, 3, 4, 5])\n",
        "D = np.diag(d)\n",
        "d = d.reshape(5,1)\n",
        "A = D + 0.1*np.random.randn(5,5)\n",
        "LpU = A - D # L+U\n",
        "b = np.ones((5,1))\n",
        "x = np.zeros((5,1))\n",
        "\n",
        "M = -LpU/d\n",
        "c = b/d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tgK6_3I1MgU",
        "outputId": "9d294429-1950-49ed-f11c-cd7da76e734a"
      },
      "source": [
        "### Solution block\n",
        "x = M@x + c\n",
        "print('x = ', x, '\\n', '   Error = ', A@x-b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  [[1.        ]\n",
            " [0.5       ]\n",
            " [0.33333333]\n",
            " [0.25      ]\n",
            " [0.2       ]] \n",
            "    Error =  [[-0.08883391]\n",
            " [-0.2159052 ]\n",
            " [ 0.01698502]\n",
            " [-0.17664335]\n",
            " [ 0.11493104]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyC742sz1Ww0"
      },
      "source": [
        "We can just play the solution block to get to the next iterate.  To reset it play the initalization block again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE-vKj-X7fQp"
      },
      "source": [
        "Notice that I used elementwise division with a column vector containing the diagonal elements of the diagonal matrix.  This is because, as I showed before, the inverse of the diagonal matrix is just the reciprocal of the diagonal entries, which is precisely what the elementwise division with the column vector gives us.  I encourage you to write it out with pen and paper to convince yourselves that this is true.  This elementwise division is much faster than what is done in the Older Notes towards the bottom of this document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owucx4Mi5pcO"
      },
      "source": [
        "## Gauss-Seidel Algorithm\n",
        "\n",
        "Similarly for Gauss-Seidel we have the recurrence relation: $x_{n+1} = -(L+D)^{-1}Ux_n + (L+D)^{-1}b$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhDdFTEb7T4S"
      },
      "source": [
        "### Initialization Block\n",
        "D = np.diag(np.array([1, 2, 3, 4, 5]))\n",
        "A = D + 0.1*np.random.randn(5,5)\n",
        "LpD = np.tril(A) # L+D\n",
        "U = A - LpD\n",
        "b = np.ones((5,1))\n",
        "x = np.zeros((5,1))\n",
        "\n",
        "M = -la.solve(LpD, U)\n",
        "c = la.solve(LpD, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8Os3ipp8X9M",
        "outputId": "a0475eb6-cdf0-4c9b-f4c7-12fdbce02f0c"
      },
      "source": [
        "### Solution block\n",
        "x = M@x + c\n",
        "print('x = ', x, '\\n', '   Error = ', A@x-b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x =  [[1.07254361]\n",
            " [0.49127848]\n",
            " [0.26801721]\n",
            " [0.27954481]\n",
            " [0.21737354]] \n",
            "    Error =  [[-1.59465774e-11]\n",
            " [-1.36196499e-10]\n",
            " [-3.04186454e-10]\n",
            " [ 1.59641189e-11]\n",
            " [ 0.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWBxySOZ9rz9"
      },
      "source": [
        "## Comparing Jacobi and Gauss-Seidel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "TQwkMcMI9238",
        "outputId": "9a1ea980-2d9f-49c2-962e-c076a0125f80"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "d = np.array([1, 2, 3, 4, 5])\n",
        "D = np.diag(d)\n",
        "d = d.reshape(5,1)\n",
        "A = D + 0.1*np.random.randn(5,5)\n",
        "LpU = A - D # L+U\n",
        "LpD = np.tril(A) # L+D\n",
        "U = A - LpD\n",
        "b = np.ones((5,1))\n",
        "x_j = np.zeros((5,1))\n",
        "x_gs = x_j.copy()\n",
        "\n",
        "M_j = -LpU/d\n",
        "c_j = b/d\n",
        "M_gs = -la.solve(LpD, U)\n",
        "c_gs = la.solve(LpD, b)\n",
        "\n",
        "TrueSol = la.solve(A, b)\n",
        "\n",
        "T = 10\n",
        "err_j = np.zeros(T)\n",
        "err_gs = err_j.copy()\n",
        "\n",
        "for i in range(T):\n",
        "  x_j = M_j@x_j + c_j\n",
        "  x_gs = M_gs@x_gs + c_gs\n",
        "  err_j[i] = np.max(np.abs(x_j - TrueSol))\n",
        "  err_gs[i] = np.max(np.abs(x_gs - TrueSol))\n",
        "\n",
        "T = np.arange(T)\n",
        "plt.semilogy(T, err_j, T, err_gs, linewidth = 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3d2b255990>,\n",
              " <matplotlib.lines.Line2D at 0x7f3d2d2c6910>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhV5bXA4d/KTMIQIAwhyUkAAUUQgRASBkVRGURRRAEZ6kit2lrb3lY72eFaO95qna2gIsggoiIOKE4ohJAwyiCISCYgCWEmhEzf/WOHNsk5OSThzGe9z8Nze/baOWeRK1nZe3/fWmKMQSmlVHAK8XYCSimlvEeLgFJKBTEtAkopFcS0CCilVBDTIqCUUkEszNsJNEdcXJxJSUnxdhpKKeVXNmzYcMgY08lRzK+KQEpKCjk5Od5OQyml/IqI5DYW09tBSikVxLQIKKVUENMioJRSQUyLgFJKBTEtAkopFcS8WgREpIeIzBGRpe78nN1FJ6iu0UZ5SinVUIuLgIjMFZFiEdnW4PhYEdklIntE5CFn72GM2WuMubOlOTRFWUUVk55Zy4i/fMI/PtxFXmmZOz9OKaX8yvnsE3gZeAqYd/aAiIQCTwNXAwVAtogsB0KBxxp8/R3GmOLz+Pwmee+rg5w8U8XJM1U8+ckenvxkD8N6dmTKkCTGXNyVqPBQd6eglFI+q8VFwBizWkRSGhxOA/YYY/YCiMgiYKIx5jFgQks+R0RmA7MBbDZbs79+SXa+3bG135ay9ttS2kaFccPABG5JTaJfQruWpKeUUn7N1c8EEoC6P3ULao85JCIdReQ5YKCIPOzoHGPMC8aYVGNMaqdODnc9N6qquoaUuGhaNfLb/vHyKuZl5jLhyS+59l9fMC9zH8fKKpv1GUop5c/kfCaL1V4JrDDG9Kt9PRkYa4y5q/b1TGCoMeb+808VUlNTTUvaRpwor2TF1gMszs5nc/5Rp+dGhIUwrl9XpqQmkd6jIyEh0tJ0lVLKJ4jIBmNMqqOYq3sHFQJJdV4n1h7zqjZR4UxLszEtzcbuohMszs7nzU2FHD5VYXduRVUNb2/ez9ub95PUoRW3DE5icmoi8e1aeSFzpZRyL1dfCYQBu4HRWD/8s4FbjTHbzztTWn4l4EhFVQ2rdhaxODuf1d+U4OzbECJwWe9OTElNYvRFXYgI0+0VSin/4exKoMVFQEQWAqOAOKAIeMQYM0dExgOPY60ImmuMebRFH+CAK4tAXfuPnmbphgKW5ORTcOS003M7xkRw48AEpgxJoleXNi7PRSmlXM0tRcAb3FUEzqqpMWTuLWVxdj4fbD9IRVWN0/MH2mKZkprEhAHdaB3pV125lVJBRIuAMSDNe8B7rKyStzYXsjg7nx0Hjjs9NzoilGv7xzNlSBKDk9sjzfwspZRyJy0CHz0CZ07AFb+CmI7N/vJthcdYnJ3PW5sLOVFe5fTcHp1imJKaxKRBiXRqE9n8XJVSysWCuwgc2gPPpENNJUS1g1G/hCF3Qmh4sz+/vLKaD7YdZHF2Ppl7S52eGxYiXHlhZ6YMSeLy3p0IC9WHyUop7wjuIvDaFNj9Qf1jcX1g7GNwwegW55JbeorXcwpYuqGAg8fLnZ7buU0kkwcncktqEilxMS3+TKWUaongLQJlh+HF0XB4r+N473Ew5lHo2LPFOVXXGFbvLmFxdj6rdhZRdY5upUO7d2DKkCTG9YunVYT2LVJKuV/wFgGAqjOQ9Tx8/leoOGEfDwmHjHth5M8gqu155Xfo5Bne3FjI4px89hSfdHpum6gwbrjUWmqqfYuUUu4U3EXgrJPF8PHvYdMCwMHfOaYzjP4tXDodQs7v/r0xho15R1mSnc+Krfs5VVHt9Px+CW2ZMsTG9QO60a5V859VKKWUM1oE6ircCB88BPlZjuPxl8K4v4Jt6Pl9Tq1TZ6p4d+sBFufksyH3iNNzI8NC/rPUNK17B11qqpRyCS0CDRkD296Aj34LxxtpbdT/Zrjq99Cu0Saozban+ARLcgp4Y0MBpQ76FtXVIy6GW4YkMWlQAp3bRLksB6VU8NEi0JiKU7DmCetPlYMVPuHRMOJBGPZDCHddA7mKqho+3lnEoib0LTq71HRqWhKX9dKlpkqp5tMicC5H86yrgu1vOo63s8E1f4C+NzR75/G5FB49zes5+byeU0DhUed9i7q2jeLmVGupaVKHaJfmoZQKXFoEmmrfGvjgF3DwK8fx5OEw9s8Qf4nLP7q6xrBmzyEWZ+fz4Y6DVFY7///LiAviuGVIEtf07aIjMpVSTmkRaI6aatg4Dz75I5Q52BUsITBoFlz5G4iJc0sKpSfP8OamQhZln3upaWx0ODcOTGDqEBt9umpXU6WUPS0CLXH6qLW3YP3zUOOgX1BkOxj1EKTd3aIWFE1hLTU9wuLsfN7ZcoDTlc6Xml6aFMvUIdrVVClVnxaB81GyG1Y+DHtWOY7H9YYxj0Gvq9yaxtkRmYuy89lyjhGZ0RGhTLgknilDbAyyxepSU6WCnBYBV9j9oVUMSvc4jvcaA2P+BHEXuD2VnQeO/2dE5rHTlU7P7dW5NVOGWF1NO8REuD03pZTv8dkiICIXAQ9gTSf72BjzrLPzvVoEAKoqYP0L8Plf4IyDGQMh4TD0+3D5z62OpW5WXlnNhzuKWJydx5o9zruahocK11zclSmpSYy4II6QEL06UCpYuGu85FxgAlB8dsZw7fGxwBNY4yVfNMb8uQnvFQLMM8bMcHae14vAWSdLrAfHG+fhsAVFdJzVgmLgDAjxzMqdvNIyluTk8/qGfIqOn3F6bkJsK25JTeLm1ES6xbpu/4NSyje5qwhcBpzE+uF9dtB8KNag+auBAqxB89OwCsJjDd7iDmNMsYhcD/wAeNUY85qzz/SZInDW/s1WC4q8TMfx+AEw9i+QnOGxlKqqa/i8tqvpx18XU+2kq2mIwKg+nZk6JIkrL+ysG9GUClBuux0kIinAijpFIAP4nTFmTO3rhwGMMQ0LgKP3etcYc62zc3yuCIDVgmL7Mvjwt3C8wPE5/W6yWlDEJnk0teIT5byxoZDF2XnsKy1zem6XtpHcPDiJKUN0I5pSgcaTRWAyMNYYc1ft65nAUGPM/Y18/ShgEhAJbDXGPO3gnNnAbACbzTY4Nze3xfm6VUUZrP0XfPk4VDnY+RvWCkb8GIb9CCI8+0PWGEPWd4dZnJ3Pe18d4ExVTaPnilgb0aal2bjqoi5EhOnVgVL+zmeLQHP55JVAQ0fzYdUjVoM6R9omwvi/woVOL3rc5tjpSt7eXMjC9fnsPODg4XYdca0juGlwIlOH2OiuE9GU8lt+cTuoKfyiCJyVuxbe/wUc3Oo4nnE/XPU7t200OxdjDFsLjrFwfR7Lt+yn7BwzD9J7dGBamo0xF3fVNhVK+RlPFoEwrAfDo4FCrAfDtxpjtrf4Q+rwqyIAVguKzQvg4z/AqRL7uC0DJr8EbeM9n1sdJ89U8c6W/Sxcn8fWgmNOz42NDmfSwESmpSXRq4u2qVDKH7hrddBCYBTWGv8i4BFjzBwRGQ88jrUiaK4x5tEWfYADflcEzio/Bqv/BuuetW9BEdMZJs+F7iO9k1sD2/cfY9H6fN7aVMiJMw7aZdSRmtyeqWk2ru2v85KV8mU+u1msufy2CJxVsAGWzLJfRSQhMPoRGP6Ay1tVt1RZhTURbVH2uSeitYkK+08Tu77dzm9Os1LK9bQI+JJTpbDsLvj2E/tYn2vhhmegVazn83Jid9EJFq7PY9nGc7epGJAUy7QhSVw3oBsx2sROKZ+gRcDX1FRbHUo//wt2O47bd4cpr0LX/l5JzZnyympWbj/Ia1l5ZH132Om5MRGhXH9pN6al2eif0E6b2CnlRVoEfNU3H8Gyu+F0g9stYVFw7f/BwOneyasJ9pacZHF2PkubMC+5b3xbpqUlMXFgAm2jvLMaSqlgpkXAlx3Jhde/B/s32ccGfQ/G/RXCfXfQfEVVDR/tKGJRdh5ffHPI6blR4SFMuMS6OtAW10p5jhYBX1d1xupBlDPXPhY/AG6ZB+1TPJ5Wc+WVlrE4J48lOQWUnHDexK53l9ZMHWJj0qAEYqO1xbVS7qRFwF9sXggrHrRvOxEVC5NegN5jvJNXM1VW1/DJ18UsWp/HZ7tLcPafWERYCNf2j2f6UBuDk9vr1YFSbqBFwJ8UbYfFM+DwXvvYZf8Dox72WHtqVyg8epol2fksycnnwLFyp+f26dKGW4fauHGQPjtQypW0CPib8mPw1r3w9Qr7WI9RcNMctw25d5fqGsPq3SW8tj6PT87R4rpVeCjXDYhn+tBkLknUlUVKnS8tAv7IGFj7JKz6HZgGfX3aJsDNr0DSEK+kdr6KjpezdEMBC9fnUXDEQcfVOi7u1pZbh9qYeGkCrXXfgVItokXAn+1bA0tvh5NF9Y+HhMOYRyFtts/sMm6umhrD6m9KeC0r75wDcGIiQpk4MIHpQ21c3M39ozuVCiRaBPzdiYPw+u2Qt9Y+1u8muO5fENna83m50MFj5SzOzmdRdt45nx0MSIpl+lAb113STXsWKdUEWgQCQXUlfPx76xZRQ3F9rF3Gnfp4Pi8Xq6qu4bNd1rODT3cVO11Z1CYqjJsGJXLrUBu9taOpUo3SIhBIdiy3HhpXnKh/PDwGJj4F/SZ5Jy83KDhSVnt1kH/OfQdDUtpz61Ab4/rF67wDpRrQIhBoDu2BJTOheId9bOgP4Oo/QFjgbMCqrK7h451FLMg6967k2OhwJtdeHfTo5N+3yJRyFS0CgajiFKz4CWxdZB9LGgo3vwxtu3k8LXfbd+gUC7PzWJpz7p5FGT06Mj3dxjV9u+qsZBXUtAgEKmNgw0vWGMvqBj8Qo+Ng8hxrX0EAOlNVzYfbi1iQlcu6vc47msa1juDm1CSmDbFh6xjtoQyV8h1aBAJd4QZY8j04ll//uITAlb+G4Q9CSOD+Jryn+CQL1+exdEOB03kHIjCyVyduTbNx1UWdCQsN3O+JUnX5bBEQkVHAH4HtwCJjzGfOztci4ETZYast9Z5V9rHeY+HG56BVe8/n5UHlldW899UBXsvKI+cc09C6tI1kSmoSU9JsJMS28lCGSnmHu2YMzwUmAMVnB83XHh8LPIE1Y/hFY8yfnbzH5cBDWDOK/9cYs8fZZ2oROIeaGmuW8WePYTesJjbZWkYaP8ArqXnaroMneC0rl2Ubnc9KDhG4ok9npqfbuLx3Z0JD/HPjnVLOuKsIXAacBOadLQIiEgrsBq4GCoBsYBpWQXiswVvcARwyxtSISBfg/4wxTqeoaBFooj2r4I277IfVhEbCtX+HQbO8k5cXlFVUsWLLARZk5bKl4JjTcxNiW3HrUBtThiQR1zrSQxkq5X5uux0kIinAijpFIAP4nTFmTO3rhwGMMQ0LQMP3iQBeM8ZMdhCbDcwGsNlsg3Nzc1ucb1A5mm8NqyncYB8bOAPG/x3Cg+s2yLbCYyzIyuPtzYWUVVQ3el54qDC2Xzwz05MZkqLtrZX/82QRmAyMNcbcVft6JjDUGHN/I18/CRgDxALP6jMBF6s6Ayt/Cdkv2se69rea0HXs6fm8vOxEeSVvb97Pa1l57Dhw3Om5vbu0ZkZ6MjcOTKCNtrdWfspni0BzaRFooS2L4Z0H7IfVhMdYTegG3+a3TejOhzGGLQXHmL8ul3e27OdMVU2j50ZHhDLx0gRmpGsDO+V/fP52UFNpETgPRTusXcalDp6997oGrn8S2nT1fF4+4mhZBUs3FLAgK4/vDp1yeu4gWywz0pMZ319bVCj/4MkiEIb1YHg0UIj1YPhWY8z2Fn9IHVoEzlP5cXj7Pti53D7Wqj1M+CdcfKPn8/IhNTWGtd+WMn9dLh/tLHLa3rp9dDg3pyYxfaiN5I4xHsxSqeZx1+qghcAoIA5riecjxpg5IjIeeBxrRdBcY8yjLfoAB7QIuIAxsPEV+OCXUOngN97+N8P4vwX8noKmOHisnEXZeSxcn0fRcecN7C7r3YkZQ21ceaFuQlO+x2c3izWXFgEXOrwX3vwB5K+zj7XpZnUkvWC05/PyQWcb2M1fl8eXe5w3sItvF8W0NBtThyTRuW2UhzJUyjktAsqxmmprPsGnj9r3HgIYcpfVkTRCb3WctbfkJAuyzt2iIixEGHNxV6an28jo0VGXmSqv0iKgnDu4Dd78PhRts4916AE3Pg9JaZ7Py4eVV1bzzpb9zM/KY0v+Uafn9uwUw/Shydw0OJF2rXSZqfI8LQLq3KrOwGd/hjWPg2mwVFJCYMSDcPlDATWnwFW+ql1m+vaWQsorG19mGhUewsQBCcxIT6Z/oi4zVZ6jRUA1Xd46ePMeOPKdfaxrf7jxBejS1/N5+YFjpytZtrGA+ety+bbE+TLTAYntmJ6erHOSlUdoEVDNc+YkfPQbyJlrHwuNgCt/Axn3QYj+8HLEGMO6vYeZvy6XldsPUuVkmWm7VuFMHpzIdJ2EptxIi4BqmW8+grfvh5MH7WO2YXDjs9A+xeNp+ZPi4+Uszs5n4fo89h8rd3ru8As6MjM9masu6qLLTJVLaRFQLVd2GN79KWxfZh+LaA1j/mR1JdXVL05VVdfwydfFzM/KY/XuEqfnxreLYvpQG1PTbNrNVLmEFgF1/r5aahWDcgcrYXqPhev+BW26eD4vP5RbeorXsvJYkpPPkbLGl5lGhIYwvn9XZg1LYWBSrC4zVS2mRUC5xvH91u2hbz+2j7XqANc9Dn0nej4vP3V2Etr8dblszHO+zLRfQltmZaRw/YBu2q9INZsWAeU6xlgPjD/8NVSW2ccvmQLj/gqtYj2fmx/bvt9aZvrmJufLTGOjw5mSmsSM9GSSOkR7MEPlz7QIKNcr/dZaSlqw3j7WNsFqO9HzSs/n5eeOlVXy+oZ8Xl2XS26pgyJbSwSu7NOZWcNSGHlBHCE6FlM5oUVAuUdNNax5Aj79E9Q4uLedNhuu+j1E6G+szVVTY1j9TQnzMnP5dFcxzv6Zdo+LYUZ6MpN1R7JqhBYB5V4Hv4Jl34diBx3DO15gtZ1IdPjfn2qCvNIy5mflsjg732m/olbhodw4KIFZGclc2LWtBzNUvk6LgHK/qjNWI7o1/wIa/DclITDyp3DZz7XtxHk4XWH1K3p57b5zjsVM696BWRnJjLm4K+G65yDoaRFQnpObaTWjO5prH4sfYF0VdL7I83kFEGMMG/OOMC8zl/e+OkBldeP/hru0jeTWtGSmpWlr62CmRUB51pkT1uqhDS/bx0IjYfRvIf1eCNHfUM9X8YlyFq3P57WsPA4eb3xHcliIMK5/PLMykklNbq97DoKMzxYBERkJTAfCgL7GmGHOztci4Gd2fwjL74eTRfax5BFwwzPQPtnzeQWgyuoaPtpRxLzMfazbe9jpuRfFt2VWRjITL+1GdESYZxJUXuWu8ZJzgQlA8dkZw7XHxwJPYI2XfNEY8+cmvNcNQBdjzPPOztMi4IfKDsOKB2HHW/axiDYw9jEYOEPbTrjQroMnmJe5jzc3FVJWUd3oeW2jwrg5NYmZ6cmkxOngoEDmriJwGXASmFdn0Hwo1qD5q4ECrEHz07AKwmMN3uIOY0xx7dctAe40xpxw9plaBPyUMVbbifd+CuXH7OMXToDrn4ToDp7PLYAdL6/kjQ0FvJqZy95Dzltbj+rTiVkZyYzq3Vn3HAQgt90OEpEUYEWdIpAB/M4YM6b29cMAxpiGBaDue9iA3xhj7j7X52kR8HPHCuHt+2Dvp/axNvFw43PQY5Snswp4NTWGNd8e4pW1uXzydRFOOltj6xDNjHQbt6QmERutK7kChSeLwGRgrDHmrtrXM4Ghxpj7nbzH74GVxpi1jcRnA7MBbDbb4NxcB6tOlP8wBrJfhA9/A1WnGwQFhv8Irvi1LiV1k/zDZSzIymNxdp7T5nWRYSFcN6AbM9OTGZCkLUD8nU8XgebQK4EAcmgPLLsL9m+yj8VfCjfNgbgLPJ9XkCivrGbF1gPMy9zH1gIHt+jq6J/QjpnpyVw3QKeg+StnRcDVa/QKgaQ6rxNrjylVX9wFcMeH1uxiGtyDPrAZnh8JG+fhtF+CarGo8FAmD05k+f0jeOu+4UwamEBEI5vKvio8xs/f2MrQP63iD+/s4NuSkx7OVrmTq68EwrAeDI/G+uGfDdxqjHHQT6D59EogQH232mo7cWK/fazvRLjuCWjV3vN5BZlDJ8+wONvac1B4tOGtuvqGX9CRGUOTuapvF92R7AfctTpoITAKiAOKgEeMMXNEZDzwONaKoLnGmEdb9AEOaBEIYGWH4Z0fwc537GNtE2DSC5AywvN5BaHqGsNnu4p5dV0un+8ucXox1qVtJFOH2JiWZqNrO92R7Kt8drNYc2kRCHDGWLeAPnjIwawCgZE/gVEPQ6h2yvSUvNIyFqzP5fWcAg6fqmj0vNAQ4eqLujAzI5lhPTvqjmQfo0VA+ZdD38Abd8KBLfaxhMEw6d/Qsafn8wpi5ZXVvL/tAPPX5bEh94jTc3t0imH60GQmD0qkXbQWbF+gRUD5n6oK+OSPsPZf9rGI1jD+bzBgmu409oId+48zPyuXt86xIzkqPITrB3RjZnoK/RPbeTBD1ZAWAeW/vv3UmmB28qB97OJJMOGfOsrSS46XV/LWpkJezczlm2LnK4YGJMUyY6iN63RGsldoEVD+7VQpLP8h7HrXPtYuyXponOy096ByI2MM6787zKvrcvlg20GqnGxJbtcqnJsHJzI9PZnu2q/IY7QIKP93dsD9yl/Z7zSWEBj5M7j8FxCqXTG9qfhEOUtql5nuP9Z4a2uAkb3imJGezOgLOxOmy0zdSouAChwlu2DpnVD0lX0scYj10LhDd8/npeqprjF88nUx82uXmToT3y6KaWk2pg7RwTfuokVABZaqM/DxHyDzKftYRBu49h8wYIrn81IO5Zae4rWsPBbn5HPUSb+isBBhzMVdmZ5uI6OHLjN1JS0CKjDt+Rje+oHjoTX9b7aKQZSuSvEV5ZXVvPfVAV5dl8umvKNOz72gc2umD7Vx0+BE2kbpMtPzpUVABa5Th6z21Ls/sI/F2mDSi2Ab6vm8lFPbCo+xICuXtzbt53Rl48tMoyNCuWFgArMykrmwa1sPZhhYtAiowPaf9tS/hqoGDyMlxHpgPPJn+tDYBx0vr2TZhgLmZ+Wx5xzLTNO6d2BWRjJjLu6q/YqaSYuACg7FO62HxsUO+hUmpVtLSXWmsU8yxrBu72HmZ+Wy8hzLTLu0jWRamo1b02z6ILmJtAio4FFZDqt+B1nP2sci21qby/pP9nhaqumKj5ezqHaZ6cHjjS8zDQsRxvbryveGpZCa3F4fJDuhRUAFn28+sh4an3KwPHHANKvtRGQbz+elmqyyuoZVO4p4JXMf6/YednruhV3bMCsjhRsGdiM6Qm/7NaRFQAWnk8Xw1r2w5yP7WPsUa3pZosN/F8rH7C46wbzMfSzb6LxfUZuoMG4enMTMDN2RXJcWARW8jIH1L1gzjavP1I9JKFzxMIz4CYRoPxt/cKK8kmUbC3klcx97S045Pfey3p2YlZ7MFRd2JjQkuG8VaRFQqmi79dC4ZKd9LHk43Pg8xCbZx5RPMsaw9ttSXlm7j1U7i3DyHJnE9q2YkZ7MlNQk2sdEeC5JH6JFQCmAytPw0W+tK4OGotpZD4373eT5vNR5KTx6mgXrclmUne908E1kWAjXDejGrIxkLkkMrs6zPlsERKQv8DugFPjYGLPU2flaBJRL7PoA3r4XykrtYwOmwbi/QpRuTPI3Z3ckz8vMZXO+8x3JlybFMisjmWsviScyLPBvBbprxvBcYAJQfHbQfO3xscATWDOGXzTG/NnJe/wUWG+M+UJElhtjrnf2mVoElMucKLJWD337sX0sNtlqRKc7jf3W1oKjzMvMZfmW/VRU1TR6XseYCKYMSWJ6ejIJsa08mKFnuasIXAacBOadLQIiEgrsBq4GCoBsYBpWQXiswVvcUft/HwHKgGHGmOHOPlOLgHKpmhrIeg5WPQLVDW4jSAhc9nO47H90p7EfO3yqgiU5+byamUvh0dONnhcicNVFXZiVkcLwCwKveZ3bbgeJSAqwok4RyAB+Z4wZU/v6YQBjTMMC0PB9QoFlxpiJDmKzgdkANpttcG5ubovzVcqhg9vgjbscPzROHGLtNO7Qw/N5KZeprjF8+nUx89blsvocra17dophZnoyNw1OpE2ANK/zZBGYDIw1xtxV+3omMNQYc7+Tr/8lEAM8a4z50tnn6ZWAcpvK07U7jZ+zj0W0tp4TXHqrzjQOAHtLTjJ/XR6vb8jnRHlVo+fFRIRy46AEZmWk0LuLf28s9Nki0FxaBJTbfbOqdqdxsX2s70SY8DhEd/B8XsrlyiqqeGvTfuZl7uPrgyecnjusZ0duH96dK/10z4GzIuDqVnyFQN3F1om1x5TyD72ugnszofc4+9iOt+HZ4bD3c8/npVwuOiKMW4faeP+BkSz5fgYTLoknrJEf8Gu/LeXueTlc8ffPePGLvRw73fhwHH/j6iuBMKwHw6OxfvhnA7caYxy0dWw+vRJQHmMMbHgJPvil/UxjBIb9EK78NYRFeiU95R5Fx8tZuD6P17LyKD5xptHzoiNCmTw4ke8NS6Fnp9YezLBl3LU6aCEwCogDioBHjDFzRGQ88DjWiqC5xphHW/QBDmgRUB5XshuW3QUHttjHuva3+g916uP5vJRbVVbXsHL7QV5Zu4/sfUecnnt5707cNjyFy3t1IsRHbxX57Gax5tIioLyiqgI+fRTWPAE0+PcSFgXX/C8MuUsfGgeobYXHeHntPpZv3k9FdeN7DnrExfC9YSncNDiR1pG+taxYi4BSrvDdF/DmPXC8wD7WawxMfBpad/J8XsojDp08w2tZecxfl+v0VlGbyDBuTk3ie8OSSe7oG51MtQgo5Sqnj8CKn8D2ZfaxmE4w8RnofY3n81IeU1FVw/vbDvDSmn1O21OIwOgLO3P78O4M6+ndDWhaBJRyJWNg62J492dQ4WBp4ZC74Zo/QnjgtiFQlk15R3h57T7e3XrA6UjMXp1bc9vwFCYNTKRVhOd7FWkRUModjuyDZbMhP8s+1ulCq3pdb90AABFTSURBVP9Q/CUeT0t5XtHxchasy2VBVh6lTjqZtmsVztQh1tCbxPbRHstPi4BS7lJdBV/8Az7/C5gGE69CwmH0byHjfghx9ZYc5YvKK6tZsfUAL635ju37jzd6XojANX27cvvwFNK6d3D7rSItAkq5W362tZT0yD77WPfL4cbnoG03j6elvMMYQ07uEV5es48Pth+k2smtor7xbblteArXD+hGVLh7bhVpEVDKE86cgPd/AZsX2MeiYuH6f1mtJ1RQKTx6mvnrclm4Po+jZY3vNO4QE8GtaTZmpCfTtV2US3PQIqCUJ21/E975MZQ7WDkycAaM/QtE+v4uU+VapyuqeXtzIS+t2ceuosZ7FYWFCOP6x3P78BQGJsW65FaRFgGlPO1YIbz5fdj3hX2sfXe46UVIdPhvUgU4YwyZe0t5aY01H9nZj+ABie24fXh3xvePJyKs5c+VtAgo5Q01NZD5JHz8R6hpcBtAQmHUQzDiJzq0JojlHy5jXuY+FmU7b2vdqU0kM4Ymc+tQG53aNL9flRYBpbzpwBZ44244tMs+lpQOk56H9ikeT0v5jlNnqli2sYCX1u5jb8mpRs+LCA1hzm2pjOzVvJ3pnmwlrZRqKH4AzP7M6i/UUP46eHYEbFmE0/sCKqDFRIYxMyOFVQ9ezit3pHFFH8c/5CPDQhhoa+/Sz9YioJQnRETDtf+AaYshOq5+rOKE9fzgjTvhdONtCFTgCwkRLu/diZduT+OTn17ObcNSiKmzw/jm1CSXN6fT20FKedrJYnj7PvjmQ/tY20Tr9lDKCM/npXzS8fJKluYUMH9dLi/fnoatY/N3GuszAaV8jTGQ/SJ8+GuoKm8QFBjxIIx6GMIivJKe8j3GmBYvF9VnAkr5GhFIuxtmfw5d+jcIGvjy/2DuNXBoj1fSU77HXa0lPFYERKSHiMwRkaXOjikVVDpfCHd/bPUXamj/Jnh+JGx4WR8aK7dpUhEQkbkiUiwi2xocHysiu0Rkj4g85Ow9jDF7jTF3nuuYUkEnLBLGPAoz34I28fVjlWXwzgOweAacKvVOfiqgNfVK4GVgbN0DIhIKPA2MA/oC00Skr4j0F5EVDf50dmnWSgWinlfAD9bCRdfZx75eAc8Og28/8XxeKqA1qQgYY1YDhxscTgP21P42XwEsAiYaY74yxkxo8Ke4pQmKyGwRyRGRnJKSkpa+jVL+IboD3PIqXP8UhDcYTXjyILx6I6z8FVQ1Pt5QqeY4n2cCCUB+ndcFtcccEpGOIvIcMFBEHm7sWEPGmBeMManGmNROnXR+qwoCIjBoJtzzBXQbZB/PfAr+fSUU7/R8birgeOzBsDGm1BhzjzGmpzHmscaOKaVqdewJd34II38GNFgZUrQNXhgFWS/oQ2N1Xs6nCBQCSXVeJ9YeU0q5Smg4jP4N3P4etEuqH6sqh/f/B167xdqAplQLnE8RyAZ6iUh3EYkApgLLXZOWUqqe5GFwz5fQb7J97JsP4ZkM2L3S83kpv9fUJaILgUygj4gUiMidxpgq4H5gJbATWGKM2e6+VJUKcq1iYfIca4B9ZNv6sbJD1hXBuz+DytPeyU/5JW0boZQ/OrIPln3f6kLaUFwfa2hN/CUeT0v5Jm0boVSgaZ8Ct70LV/zKGlBT16Fd8OJoWPukNdhGKSe0CCjlr0LD4PKfWyuI2nevH6uusJrTvXoDHN/vnfyUX9AioJS/S0y19hRcOsM+9t3n1k7jne94Pi/lF7QIKBUIItvADU/DzS9DVGz92OkjVu+h5T+EMye9kp7yXVoElAokF99o9R9KGWkf2zgPnr8MCjd4Pi/ls7QIKBVo2iXArOVw9R8gJLx+7PC3MOcaWP13qKn2Tn7Kp2gRUCoQhYTA8AfgrlXQsVf9WE0VfPJHeHkCHM3zTn7KZ2gRUCqQdbsUvr8aUu+wj+WthWdHwFc60ymYaRFQKtBFRMOEf8K0RRDdsX7szDF4405YNhvKj3knP+VVWgSUChZ9xsEPMqHnaPvY1sXw3AjIc7ADWQU0LQJKBZM2XWD6Uhj7FwiNrB87mgcvjYNP/wTVVd7JT3mcFgGlgk1ICKTfA7M/hc4X14+ZGvj8LzB3DBze6538lEdpEVAqWHW5GO7+BNLvtY8V5sBzI2HTfB1aE+C0CCgVzMKjYOxjMOMNaN2lfqziJLx9HyyZBWUNR4yrQKFFQCkFF1xl7TTuM94+tnO51X9o72ceT0u5nxYBpZQlJg6mvgYTHofw6PqxEwdg3kRY+SuoOuOd/JRbaBFQSv2XCKTebm0wi7/UPp75FPx7NBTv9Hxuyi08VgREpIeIzBGRpXWOXSQiz4nIUhH5gadyUUqdQ1wvuPMjGPETQOrHir6CF0ZB1vP60DgANHXG8FwRKRaRbQ2OjxWRXSKyR0QecvYexpi9xpg7GxzbaYy5B7gFGN7c5JVSbhQWAVc9Yk0wa5dUP1ZVDu//HBZMhhNF3slPuURTrwReBsbWPSAiocDTwDigLzBNRPqKSH8RWdHgT+fG3lhErgfeBd5r0d9AKeVeKcPhni+h/832sT2r4NkM2PW+5/NSLtGkImCMWQ00XCOWBuyp/Q2/AlgETDTGfGWMmdDgT7GT915ujBkHTHcUF5HZIpIjIjklJSVN+1sppVyrVaw1vH7SvyGybf1YWSksnArv/BgqTnknP9Vi5/NMIAHIr/O6oPaYQyLSUUSeAwaKyMO1x0aJyL9E5HkauRIwxrxgjEk1xqR26tTpPNJVSp23S26xrgpsw+xjG16yhtbs3+T5vFSLhXnqg4wxpcA9DY59BnzmqRyUUi7QPhluWwFf/hM+e8yaT3BW6R548Sq44pcw/McQEuq9PFWTnM+VQCFQ92lRYu0xpVSgCwmFy35mrSDq0LN+rKYKPv4DvHIdHM13/PXKZ5xPEcgGeolIdxGJAKYCy12TllLKLyQMgnu+gMG32cdy18Czw3VojY9r6hLRhUAm0EdECkTkTmNMFXA/sBLYCSwxxmx3X6pKKZ8UEQPXPWHtNm7VoX7s7NCaN+7WoTU+SowfbfZITU01OTk53k5DKdWYEwfhrXvh24/tY+1sMOl5SHbwUFm5lYhsMMakOopp2willOu06dr40JpjefDytdbzgupK7+Sn7GgRUEq51n+G1nwGXfrVj5ka+OIfMOcaOLTHG9mpBrQIKKXco0tfuOtjyLjfPrZ/Izw/Eja8rP2HvEyLgFLKfcKjYMyjMPMtaBNfP1ZZBu88AItnwKlS7+SntAgopTyg5xXW0JqLrrOPfb3C6j+0Z5Xn81JaBJRSHhLdAW55Fa5/CsJj6sdOFsH8m+D9X0BluXfyC1JaBJRSniMCg2ZaG8wSHKxYzHoO/n0FFOmWI0/RIqCU8ryOPeGOD+DyX4A0+DFUvMMaWpP5NNTUeCW9YKJFQCnlHaHhVqO529+HWFv9WHUFrPwlvDoRDn/nnfyChBYBpZR32dLhnjUwYJp97LvV8OwwWPcs1FR7PrcgoEVAKeV9UW3hxudg8ksQ1a5+rLIMPngI5o6Fkt3eyS+AaRFQSvmOfpOspaQ9rrCPFayH50ZYO4617YTLaBFQSvmWdokw801rKWlkg6uC6jNW76F/XwkHtnonvwCjRUAp5XvOLiW9Lwv6jLePH9xqLSX95H+h6ozn8wsgWgSUUr6rbbw1p+CmORDdsX6spgpW/82aa1ygLeZbSouAUsq3iUD/yXDfeuh3k3285GuYczWs/BVUlHk+Pz/nsSIgIj1EZI6ILK1zbJSIfCEiz4nIKE/lopTyQzFxMHkuTF0IrbvWj5kayHzKWk6670vv5Oenmjpecq6IFIvItgbHx4rILhHZIyIPOXsPY8xeY8ydDQ8DJ4EooKA5iSulgtSF461nBQNn2MeOfGcNrlnxIJQf93xufqipVwIvA2PrHhCRUOBpYBzQF5gmIn1FpL+IrGjwp3Mj7/uFMWYc8Avg9y37Kyilgk6rWJj4NMxYZo2tbChnLjyTAd9oZ9JzaVIRMMasBg43OJwG7Kn9Db8CWARMNMZ8ZYyZ0OBPcSPve7YxyBEg0tE5IjJbRHJEJKekpKRJfymlVJC4YDTcmwlps+1jxwtgwU3w5j1Q1vDHlzrrfJ4JJAD5dV4X1B5zSEQ6ishzwEARebj22CQReR54FXjK0dcZY14wxqQaY1I7dep0HukqpQJSZGsY/zerB1GHnvbxLQvh6aGwY7nnc/MDYZ76IGNMKXBPg2PLgGWeykEpFcCSh8EP1sBnj8HaJ62HxWedKoYlM6HvRBj/d2jd2B3q4HM+VwKFQFKd14m1x5RSyjvCW8HVf4C7VkHnvvbxHW/D02mwZbHONq51PkUgG+glIt1FJAKYCuj1llLK+xIGw+zPYdTDEBJeP3b6CLw5G16bAsf099amLhFdCGQCfUSkQETuNMZUAfcDK4GdwBJjjI4DUkr5hrAIGPUQfP9z6DbQPv7NSngmHXJeCuqrAjF+9JdPTU01OTm6PVwp1UzVVbDuafj0T1DlYIZxyki4/kno0N3zuXmAiGwwxjiY56ltI5RSwSA0DIY/YA2vsWXYx/d9Ye02znwm6IbXaBFQSgWPuAvgtvesFULhMfVjlWWw8uHa4TW7vJOfF2gRUEoFl5AQSLvb2mTmbHjN6r8HxfAafSaglApexsDmBdZQ+/Jj9vGul8CEf0L7FI+n5pCEQHSH5n+Zk2cCWgSUUur4AXj3p7DrXW9n4lyHnvCjjc3+Mn0wrJRSzrSNh6kLrFbVDYfXBDgtAkopBdbwmn431Q6vmeztbDzGY72DlFLKL8TEweQ5VkFY+yQc8qGVQq1iXf6WWgSUUsqRC8dbfwKc3g5SSqkgpkVAKaWCmBYBpZQKYloElFIqiGkRUEqpIKZFQCmlgpgWAaWUCmJ+1TtIREqA3BZ+eRxwyIXp+Dv9ftSn34//0u9FfYHw/Ug2xnRyFPCrInA+RCSnsQZKwUi/H/Xp9+O/9HtRX6B/P/R2kFJKBTEtAkopFcSCqQi84O0EfIx+P+rT78d/6feivoD+fgTNMwGllFL2gulKQCmlVANaBJRSKogFRREQkbEisktE9ojIQ97Ox5tEJElEPhWRHSKyXUQe8HZO3iYioSKySURWeDsXbxORWBFZKiJfi8hOEcnwdk7eJCIP1v472SYiC0Ukyts5uVrAFwERCQWeBsYBfYFpItLXu1l5VRXwU2NMXyAduC/Ivx8ADwA7vZ2Ej3gC+MAYcyEwgCD+vohIAvAjINUY0w8IBaZ6NyvXC/giAKQBe4wxe40xFcAiYKKXc/IaY8wBY8zG2v99AusfeYJ3s/IeEUkErgVe9HYu3iYi7YDLgDkAxpgKY8xR72bldWFAKxEJA6KB/V7Ox+WCoQgkAPl1XhcQxD/06hKRFGAgkOXdTLzqceDnQI23E/EB3YES4KXa22MvikiMt5PyFmNMIfB3IA84ABwzxnzo3axcLxiKgHJARFoDbwA/NsYc93Y+3iAiE4BiY8wGb+fiI8KAQcCzxpiBwCkgaJ+hiUh7rLsG3YFuQIyIzPBuVq4XDEWgEEiq8zqx9ljQEpFwrAKwwBizzNv5eNFw4HoR2Yd1m/BKEZnv3ZS8qgAoMMacvTJcilUUgtVVwHfGmBJjTCWwDBjm5ZxcLhiKQDbQS0S6i0gE1oOd5V7OyWtERLDu+e40xvyft/PxJmPMw8aYRGNMCtZ/F58YYwLuN72mMsYcBPJFpE/todHADi+m5G15QLqIRNf+uxlNAD4oD/N2Au5mjKkSkfuBlVhP9+caY7Z7OS1vGg7MBL4Skc21x35pjHnPizkp3/FDYEHtL0x7gdu9nI/XGGOyRGQpsBFrVd0mArCFhLaNUEqpIBYMt4OUUko1QouAUkoFMS0CSikVxLQIKKVUENMioJRSQUyLgFJKBTEtAkopFcT+H1bMXhWxQby5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwHV7l7RA-WA"
      },
      "source": [
        "Notice that we used the function \"semilogy\", which gives us a log scale on the vertical axis (the ordinate).  If we had used the usual plot function it would have looked like utter ....  Compare:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "HjQ91M9iA7Mw",
        "outputId": "b963399d-7a9f-40ab-959a-9dfc4b6a9403"
      },
      "source": [
        "plt.plot(T, err_j, T, err_gs, linewidth = 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3d2ab67990>,\n",
              " <matplotlib.lines.Line2D at 0x7f3d2a8964d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdT8O3XkFV5Y"
      },
      "source": [
        "# Older notes: \n",
        "## Jacobi Method\n",
        "One of the easiest types of systems to solve is a diagonal system.  That is, if $P$ is a matrix with zeros everywhere except the main diagonal, then it is very fast to solve $P\\mathbf{x} = \\mathbf{c}$.  (You wrote your own diagonal system solver in the last activity, but the backslash command will be fast enough for our purposes.)  It is easy to check that we can solve such a system in $\\mathcal{O}(N)$ steps, since finding each variable only involves a single division step.  It would therefore be convenient to choose a diagonal matrix for $P$ in our splitting method.  If we choose $P$ as the diagonal matrix with the same diagonal entries as $A$, then our method is called the *Jacobi method*.  That is, we should choose\n",
        "\n",
        "$P = \\left(\\begin{array}{c} 6 & 0 & 0 \\\\ 0 & 8 & 0 \\\\ 0 & 0 & 9 \\end{array}\\right)$ and $T = \\left(\\begin{array}{c} 0 & 1 & 1 \\\\ 1 & 0 & 2 \\\\ 2 & 3 & 0 \\end{array}\\right)$.  \n",
        "\n",
        "(Remember, we have to choose $T = A - P$ to satisfy the requirement for a matrix splitting method.)  We could type these matrices out in MATLAB, but there is a convenient function in python that will make this easier.  We encountered the `diag` function in the last lecture when we made a diagonal matrix with entries from a 1D array.  This function has another use when we use a 2D array as an argument: It creates a 1D array with all of the diagonal entries.  For example, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJEyQHp4FV5Z",
        "outputId": "0e6c72bd-5a28-46ab-e5f0-14811f83c758"
      },
      "source": [
        "np.diag(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En3teEnGFV5a"
      },
      "source": [
        "In other words, if you give `diag` a matrix, it returns a 1D array with the diagonal entries.  If you give `diag` a 1D array, it returns a diagonal matrix with those entries.  Therefore, if we use `diag` twice on `A`, we will get a diagonal matrix with the same diagonal entries as `A`.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17vAtHeJFV5a",
        "outputId": "095c1694-ccef-48f9-86a0-6dee3f445b9a"
      },
      "source": [
        "P = np.diag(np.diag(A))\n",
        "print(P)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6 0 0]\n",
            " [0 8 0]\n",
            " [0 0 9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tPCdpxwFV5a",
        "outputId": "012f4264-c4a4-4ce0-9f61-46a777246c03"
      },
      "source": [
        "T = A - P\n",
        "print(T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 1]\n",
            " [1 0 2]\n",
            " [2 3 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBRxlmmdFV5b"
      },
      "source": [
        "We can check that our method will converge by finding the magnitude of all the eigenvalues of $M = -P^{-1}T$.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRRMF-WxFV5b",
        "outputId": "c52be780-d1e3-428f-96f8-69466dcbd5e5"
      },
      "source": [
        "M = -scipy.linalg.solve(P, T)\n",
        "w, V = np.linalg.eig(M)\n",
        "print(np.abs(w))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.42362039 0.13048966 0.29313073]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_6omzAsFV5c",
        "outputId": "795f2b89-4fd8-4526-8a46-2e4b5fd9ca45"
      },
      "source": [
        "print(np.max(np.abs(w)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4236203869607174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPNJ9Ee5FV5c"
      },
      "source": [
        "Since the largest eigenvalue (and therefore all of the eigenvalues) is smaller than 1, the Jacobi method will converge for this problem.  \n",
        "\n",
        "To begin a matrix splitting method, we need to make some initial guess for our solution.  We already showed that the choice of guess does not affect the convergence of our method, so it does not particularly matter what we choose here.  It is common to choose a random vector in situations like this, but we will choose a vector of all ones for no particular reason.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41VaenL0FV5g"
      },
      "source": [
        "x0 = np.ones((3, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rywJqrweFV5g"
      },
      "source": [
        "We can now use the equation \n",
        "\n",
        "$\\mathbf{x}_k = P^{-1}\\left(-T\\mathbf{x}_{k-1} + \\mathbf{b}\\right)$\n",
        "\n",
        "to implement our algorithm.  Remember, you should use the `solve_triangular` function in place of matrix inverses in python for this problem.  (There is no builtin diagonal system solver in the scipy package, but we could also use the one we wrote.  For our purposes, `solve_triangular` will be fast enough.)  We could therefore find the next guess using "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGVWUG0lFV5h",
        "outputId": "24e53f16-96de-45ac-a792-7a4a83b8ff3e"
      },
      "source": [
        "x1 = scipy.linalg.solve_triangular(P, -T @ x0 + b)\n",
        "print(x1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.33333333]\n",
            " [-1.375     ]\n",
            " [-1.44444444]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIxIhw3SFV5h"
      },
      "source": [
        "This is closer to the true solution than before, so it seems like we are on the right track.  We can continue this process with "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BXt1RYIFV5h",
        "outputId": "f550b389-1a18-4eb4-92e0-f53c2fb162bc"
      },
      "source": [
        "x2 = scipy.linalg.solve_triangular(P, -T @ x1 + b)\n",
        "print(x2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.13657407]\n",
            " [-0.80555556]\n",
            " [-0.72685185]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcXorAimFV5i",
        "outputId": "af3392bf-3f65-43bc-bb29-01721626e84c"
      },
      "source": [
        "x3 = scipy.linalg.solve_triangular(P, -T @ x2 + b)\n",
        "print(x3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.9220679 ]\n",
            " [-1.0853588 ]\n",
            " [-1.09516461]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaEd4v6VFV5i",
        "outputId": "879e66cf-770e-4661-bcf2-02412de34a9e"
      },
      "source": [
        "x4 = scipy.linalg.solve_triangular(P, -T @ x3 + b)\n",
        "print(x4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.03008723]\n",
            " [-0.96646734]\n",
            " [-0.95422882]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTCxncBpFV5i"
      },
      "source": [
        "These first few guesses do seem to confirm that we are converging to the correct solution, but it should also be clear that we don't want to continue this process by hand.  Since we are repeating almost the same code over and over again, it is probably a good idea to use a loop.  Since we don't know how many steps we need, this is actually a good place for a while loop, but we will start with a for loop because they tend to be easier to understand.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-wkRKrJFV5j"
      },
      "source": [
        "### Jacobi method (version 1)\n",
        "As a (very rough) first pass, we can try the following: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N80eHS-gFV5j",
        "outputId": "99a92850-2e8d-4026-d5b6-77514ac0529c"
      },
      "source": [
        "A = np.array([[6, 1, 1], [1, 8, 2], [2, 3, 9]])\n",
        "b = np.array([[10], [-8], [-8]])\n",
        "P = np.diag(np.diag(A))\n",
        "T = A - P\n",
        "\n",
        "x0 = np.ones((3, 1))\n",
        "for k in range(100):\n",
        "    x1 = scipy.linalg.solve_triangular(P, -T @ x0 + b)\n",
        "    \n",
        "print(x1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.33333333]\n",
            " [-1.375     ]\n",
            " [-1.44444444]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApX4HWiIFV5j"
      },
      "source": [
        "This doesn't really do what we want, since it just calculates the first guess over and over again.  We need to somehow keep track of our guesses as we go.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQWBVeCYFV5j"
      },
      "source": [
        "### Jacobi method (version 2)\n",
        "There are several ways to do this, but we will try storing all of our guesses in a big matrix.  (We actually only ever need the last two guesses, but it might be convenient to have a record of all our guesses for analysis.)  In particular, we will make a matrix `X` where every column is supposed to represent one of our guesses.  Since our loop needs access to the initial guess, we will need to put this initial guess into our matrix as well.  \n",
        "\n",
        "Remember that we always want to initialize our matrices by creating an \"empty\" matrix of the right size before we start our loop.  However, we don't know how many guesses we will actually need, so we don't know how big to make our matrix.  There is not really an ideal way around this problem, but we will start by making space for 101 columns, because or loop repeats 100 times (plus one column for the initial guess).  Note that it would be fine to make `X` bigger, but our code will fail if we initialize `X` with fewer than 101 columns, because at some point in our loop we would try to fill in a column past the end of our matrix.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wnZ4xquFV5k"
      },
      "source": [
        "A = np.array([[6, 1, 1], [1, 8, 2], [2, 3, 9]])\n",
        "b = np.array([[10], [-8], [-8]])\n",
        "P = np.diag(np.diag(A))\n",
        "T = A - P\n",
        "\n",
        "x0 = np.ones((3, 1))\n",
        "X = np.zeros((3, 101))\n",
        "X[:, 0:1] = x0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKpx-5EHFV5l"
      },
      "source": [
        "The last line uses a trick we mentioned briefly in the first week.  The problem is that python treats `X[:, 0]` as a 1D array, but x0 is a column vector (i.e., a 2D array with three rows and one column).  If you try to write `X[:, 0] = x0`, then python will throw an error because the shapes on the left and right do not match.  We could fix this by reshaping x0 to a 1D array with the code \n",
        "\n",
        "`X[:, 0] = x0.reshape(3)` or `X[:, 0] = np.reshape(x0, (3))`\n",
        "\n",
        "but it is more convenient to replace `X[:, 0]` with `X[:, 0:1]`.  Remember, `0:1` means \"start at index zero, then go up until just before you reach index one.\"  Of course, that just means index 0, but the fact that we used a colon (or in other words, a slice) tells python to pay attention to the shape and treat everything as 2D arrays.  \n",
        "\n",
        "We are now in a position to fix our loop.  At every step, we want to update the next guess using our last guess.  Turning this into code, we have "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gILsP_JoFV5l"
      },
      "source": [
        "for k in range(100):\n",
        "    X[:, (k+1):(k+2)] = scipy.linalg.solve_triangular(P, -T @ X[:, k:(k+1)] + b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXzAsoc3FV5l"
      },
      "source": [
        "We have used the same trick twice here.  We would really like to write \n",
        "\n",
        "`X[:, k+1] = scipy.linalg.solve_triangular(P, -T @ X[:, k] + b)`\n",
        "\n",
        "but we run into the same issue where python has difficulty converting between 1D and 2D arrays.  The code `X[:, k]` makes a 1D array, but the `@` operator expects 2D arrays.  The solve_triangular function then produces a 2D array (a column vector), which we can't assign to `X[:, k+1]` because that is a 1D array.  As before, we could also fix this with a couple reshape commands, but this \"slice trick\" is a lot more convenient.  (It's actually faster too, since the reshape command copies the array in question.)\n",
        "\n",
        "If you print out the matrix `X`, you should see that the columns are now filled with our guesses (and the first five columns match our old answers).  You should also notice that our method converged successfully, since the last column is the true solution to $A\\mathbf{x} = \\mathbf{b}$.  In fact, our method seemed to converge in much fewer than 100 steps, since the last twenty or so columns are all exactly the same.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw9D4OZtFV5m"
      },
      "source": [
        "### Jacobi method (version 3)\n",
        "The reason our method kept running after finding the correct answer is because we didn't include our stopping criterion.  Remember, we decided to stop if the difference between our last two guesses was smaller than some predefined tolerance.  We can fix our code by adding an `if` `break` combination, just like in the bisection method.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa_E_RGJFV5o"
      },
      "source": [
        "A = np.array([[6, 1, 1], [1, 8, 2], [2, 3, 9]])\n",
        "b = np.array([[10], [-8], [-8]])\n",
        "P = np.diag(np.diag(A))\n",
        "T = A - P\n",
        "\n",
        "tolerance = 1e-8\n",
        "x0 = np.ones((3, 1))\n",
        "X = np.zeros((3, 101))\n",
        "X[:, 0:1] = x0\n",
        "\n",
        "for k in range(100):\n",
        "    X[:, (k+1):(k+2)] = scipy.linalg.solve_triangular(P, -T @ X[:, k:(k+1)] + b)\n",
        "    if np.max(np.abs(X[:, k+1] - X[:, k])) < tolerance:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dHTrPdLFV5p"
      },
      "source": [
        "This appears to have worked.  It converged to within about 8 decimal places of the correct answer after only 25 guesses (including the initial guess).  The rest of the matrix `X` is all zeros, because our loop stopped before filling in those columns.  We can chop off those extra zeros with the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld7lktNmFV5p",
        "outputId": "3b8dffe9-423c-4141-eb95-d476b1e07672"
      },
      "source": [
        "X = X[:, :(k+2)]\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.          1.33333333  2.13657407  1.9220679   2.03008723  1.98678269\n",
            "   2.00551122  1.99764614  2.00099237  1.99957832  2.00017827  1.99992438\n",
            "   2.000032    1.99998643  2.00000574  1.99999757  2.00000103  1.99999956\n",
            "   2.00000019  1.99999992  2.00000003  1.99999999  2.00000001  2.\n",
            "   2.        ]\n",
            " [ 1.         -1.375      -0.80555556 -1.0853588  -0.96646734 -1.0152037\n",
            "  -0.99388193 -1.00269017 -0.99888975 -1.000479   -0.99979964 -1.00008563\n",
            "  -0.99996395 -1.00001534 -0.99999352 -1.00000275 -0.99999884 -1.00000049\n",
            "  -0.99999979 -1.00000009 -0.99999996 -1.00000002 -0.99999999 -1.\n",
            "  -1.        ]\n",
            " [ 1.         -1.44444444 -0.72685185 -1.09516461 -0.95422882 -1.01786361\n",
            "  -0.99199492 -1.00326407 -0.9985802  -1.00059061 -0.99974663 -1.0001064\n",
            "  -0.99995465 -1.00001913 -0.99999187 -1.00000344 -0.99999854 -1.00000062\n",
            "  -0.99999974 -1.00000011 -0.99999995 -1.00000002 -0.99999999 -1.\n",
            "  -1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIk8CSrnFV5q"
      },
      "source": [
        "(The term `:(k+2)` means \"start at index 0 (the first column index) and go up to but not including index k+2.\"  We have to include index k+1 because that is the last column we filled in our loop.)\n",
        "\n",
        "This is essentially a working version of the Jacobi method, but there is one more issue to watch out for.  It is entirely possible to come up with problems that take many more steps to converge.  However, our code will only run for 101 guesses before stopping (because the for loop only runs for 100 steps).  If that is not enough guesses, then our code will produce the wrong answer.  You can always tell if this happened, because after running the script `k` would be 99.  \n",
        "\n",
        "A simple fix is just to make our for loop run for more steps (and initialize the matrix `X` with more columns), but it is pretty inconvenient to have to run our code over and over again to find the right number of steps.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9VExl6vFV5q"
      },
      "source": [
        "### Jacobi method (version 4)\n",
        "A better solution is probably to use a while loop instead of a for loop.  This will avoid the issue of needing to guess a maximum number of steps, at the cost of complicating our code substantially.  As a first pass, we could try this: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1931-Co1FV5q",
        "outputId": "577d09c0-29a0-47e0-8c9e-dee6a82604e1"
      },
      "source": [
        "A = np.array([[6, 1, 1], [1, 8, 2], [2, 3, 9]])\n",
        "b = np.array([[10], [-8], [-8]])\n",
        "P = np.diag(np.diag(A))\n",
        "T = A - P\n",
        "\n",
        "tolerance = 1e-8\n",
        "err = tolerance + 1\n",
        "x0 = np.ones((3, 1))\n",
        "X = np.zeros((3, 101))\n",
        "X[:, 0:1] = x0\n",
        "\n",
        "k = 0\n",
        "while err >= tolerance:\n",
        "    X[:, (k+1):(k+2)] = scipy.linalg.solve_triangular(P, -T @ X[:, k:(k+1)] + b)\n",
        "    err = np.max(np.abs(X[:, k+1] - X[:, k]))\n",
        "    k = k + 1\n",
        "X = X[:, :(k+1)]\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.          1.33333333  2.13657407  1.9220679   2.03008723  1.98678269\n",
            "   2.00551122  1.99764614  2.00099237  1.99957832  2.00017827  1.99992438\n",
            "   2.000032    1.99998643  2.00000574  1.99999757  2.00000103  1.99999956\n",
            "   2.00000019  1.99999992  2.00000003  1.99999999  2.00000001  2.\n",
            "   2.          0.        ]\n",
            " [ 1.         -1.375      -0.80555556 -1.0853588  -0.96646734 -1.0152037\n",
            "  -0.99388193 -1.00269017 -0.99888975 -1.000479   -0.99979964 -1.00008563\n",
            "  -0.99996395 -1.00001534 -0.99999352 -1.00000275 -0.99999884 -1.00000049\n",
            "  -0.99999979 -1.00000009 -0.99999996 -1.00000002 -0.99999999 -1.\n",
            "  -1.          0.        ]\n",
            " [ 1.         -1.44444444 -0.72685185 -1.09516461 -0.95422882 -1.01786361\n",
            "  -0.99199492 -1.00326407 -0.9985802  -1.00059061 -0.99974663 -1.0001064\n",
            "  -0.99995465 -1.00001913 -0.99999187 -1.00000344 -0.99999854 -1.00000062\n",
            "  -0.99999974 -1.00000011 -0.99999995 -1.00000002 -0.99999999 -1.\n",
            "  -1.          0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LV7cDr3FV5r"
      },
      "source": [
        "There is actually a serious problem with this code, but before we discuss it we should see why we made the changes we did.  In particular, there are a few important differences between this and the for loop version.  First, we have to keep track of `k` ourselves, which means we ahve to get a starting value and to increment it in the loop.  Second, the stopping condition is now at the top of the while loop, but it is backwards.  This is because the `if` `break`combo tests when to stop, but the while loop condition tests when to keep going.  We should keep guessing as long as our error is larger than the tolerance.  Third, we initialized the error to a strange value: `tolerance + 1`.  The reason for this is that the while loop needs to know the error in order to test its condition.  We don't actually have an error before we make our second guess, so we have to make up an error value that will ensure we continue.  Since `tolerance + 1` is greater than `tolerance`, we know that the while loop will execute at least one step.  \n",
        "\n",
        "The problem with this code is that it still won't actually work if the loop takes more than 100 iterations.  To see what goes wrong, let's initialize our matrix `X` as a $3\\times 11$ matrix instead of $3\\times 101$.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awFsJjJiFV5r",
        "outputId": "f074a9d5-afc0-485d-849c-5c2953e130ef"
      },
      "source": [
        "A = np.array([[6, 1, 1], [1, 8, 2], [2, 3, 9]])\n",
        "b = np.array([[10], [-8], [-8]])\n",
        "P = np.diag(np.diag(A))\n",
        "T = A - P\n",
        "\n",
        "tolerance = 1e-8\n",
        "err = tolerance + 1\n",
        "x0 = np.ones((3, 1))\n",
        "X = np.zeros((3, 11))\n",
        "X[:, 0:1] = x0\n",
        "\n",
        "k = 0\n",
        "while err >= tolerance:\n",
        "    X[:, (k+1):(k+2)] = scipy.linalg.solve_triangular(P, -T @ X[:, k:(k+1)] + b)\n",
        "    err = np.max(np.abs(X[:, k+1] - X[:, k]))\n",
        "    k = k + 1\n",
        "X = X[:, :(k+1)]\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 11 is out of bounds for axis 1 with size 11",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-08666e691188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve_triangular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 11 is out of bounds for axis 1 with size 11"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN3iSlsYFV5r"
      },
      "source": [
        "Python throws an error once k reaches 10, because we try to fill in column index 11 (the 12th column of X) when it doesn't actually exist.  To fix this, we need to expand the size of our array as we go.  There are several ways to do this, but all of them are lacking in either elegance or efficiency.  We will use the `numpy` function `hstack`.  This is essentially the same thing a `append`, but for 2D arrays.  (The `append` function only really works on 1D arrays, while `hstack` appends columns to the end of a 2D array.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE9rCTDsFV5r",
        "outputId": "8ce8f029-8a93-40a5-f1e9-672de1fd21d6"
      },
      "source": [
        "A = np.array([[6, 1, 1], [1, 8, 2], [2, 3, 9]])\n",
        "b = np.array([[10], [-8], [-8]])\n",
        "P = np.diag(np.diag(A))\n",
        "T = A - P\n",
        "\n",
        "tolerance = 1e-8\n",
        "err = tolerance + 1\n",
        "x0 = np.ones((3, 1))\n",
        "X = np.zeros((3, 1))\n",
        "X[:, 0:1] = x0\n",
        "\n",
        "k = 0\n",
        "while err >= tolerance:\n",
        "    X = np.hstack((X, scipy.linalg.solve_triangular(P, -T @ X[:, k:(k+1)] + b)))\n",
        "    err = np.max(np.abs(X[:, k+1] - X[:, k]))\n",
        "    k = k + 1\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.          1.33333333  2.13657407  1.9220679   2.03008723  1.98678269\n",
            "   2.00551122  1.99764614  2.00099237  1.99957832  2.00017827  1.99992438\n",
            "   2.000032    1.99998643  2.00000574  1.99999757  2.00000103  1.99999956\n",
            "   2.00000019  1.99999992  2.00000003  1.99999999  2.00000001  2.\n",
            "   2.        ]\n",
            " [ 1.         -1.375      -0.80555556 -1.0853588  -0.96646734 -1.0152037\n",
            "  -0.99388193 -1.00269017 -0.99888975 -1.000479   -0.99979964 -1.00008563\n",
            "  -0.99996395 -1.00001534 -0.99999352 -1.00000275 -0.99999884 -1.00000049\n",
            "  -0.99999979 -1.00000009 -0.99999996 -1.00000002 -0.99999999 -1.\n",
            "  -1.        ]\n",
            " [ 1.         -1.44444444 -0.72685185 -1.09516461 -0.95422882 -1.01786361\n",
            "  -0.99199492 -1.00326407 -0.9985802  -1.00059061 -0.99974663 -1.0001064\n",
            "  -0.99995465 -1.00001913 -0.99999187 -1.00000344 -0.99999854 -1.00000062\n",
            "  -0.99999974 -1.00000011 -0.99999995 -1.00000002 -0.99999999 -1.\n",
            "  -1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIWMFtEfFV5s"
      },
      "source": [
        "**Warning:** This code is substantially slower than the corresponding for loop version, because the `hstack` function copies our matrix `X` at every step.  This loss of speed is unavoidable if we want to store all of our guesses without first initializing a big enough array.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3ov8qGkFV5s"
      },
      "source": [
        "The one thing you should always be wary of with while loops is the risk of infinite loops.  This is particularly important with matrix splitting methods, because we know that they might not converge even if the system $A\\mathbf{x} = \\mathbf{b}$ has a solution.  For example, if we made a mistake when entering $A$ and accidentally wrote `A = np.array([[1, 6, 1], [1, 8, 2], [2, 3, 9]])` then you would find that your code ran forever.  Even though the only difference between this and the previous version is that we swapped two entries of $A$.  (Actually, this particular example does eventually stop by throwing an error, but it takes many thousands of steps.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUgwAb3oFV5s"
      },
      "source": [
        "### Jacobi method (version 5)\n",
        "We know one way to fix this: We could first test the eigenvalues of $M$ to see if they are less than one.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvEnrpEWFV5s",
        "outputId": "16dfbb3e-00f0-4fb8-9b2d-4657ec90b729"
      },
      "source": [
        "A = np.array([[6, 1, 1], [1, 8, 2], [2, 3, 9]])\n",
        "b = np.array([[10], [-8], [-8]])\n",
        "P = np.diag(np.diag(A))\n",
        "T = A - P\n",
        "\n",
        "tolerance = 1e-8\n",
        "err = tolerance + 1\n",
        "x0 = np.ones((3, 1))\n",
        "X = np.zeros((3, 1))\n",
        "X[:, 0:1] = x0\n",
        "\n",
        "k = 0\n",
        "M = -scipy.linalg.solve(P, T)\n",
        "w, V = np.linalg.eig(M)\n",
        "if np.max(np.abs(w)) < 1:\n",
        "    while err >= tolerance:\n",
        "        X = np.hstack((X, scipy.linalg.solve_triangular(P, -T @ X[:, k:(k+1)] + b)))\n",
        "        err = np.max(np.abs(X[:, k+1] - X[:, k]))\n",
        "        k = k + 1\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.          1.33333333  2.13657407  1.9220679   2.03008723  1.98678269\n",
            "   2.00551122  1.99764614  2.00099237  1.99957832  2.00017827  1.99992438\n",
            "   2.000032    1.99998643  2.00000574  1.99999757  2.00000103  1.99999956\n",
            "   2.00000019  1.99999992  2.00000003  1.99999999  2.00000001  2.\n",
            "   2.        ]\n",
            " [ 1.         -1.375      -0.80555556 -1.0853588  -0.96646734 -1.0152037\n",
            "  -0.99388193 -1.00269017 -0.99888975 -1.000479   -0.99979964 -1.00008563\n",
            "  -0.99996395 -1.00001534 -0.99999352 -1.00000275 -0.99999884 -1.00000049\n",
            "  -0.99999979 -1.00000009 -0.99999996 -1.00000002 -0.99999999 -1.\n",
            "  -1.        ]\n",
            " [ 1.         -1.44444444 -0.72685185 -1.09516461 -0.95422882 -1.01786361\n",
            "  -0.99199492 -1.00326407 -0.9985802  -1.00059061 -0.99974663 -1.0001064\n",
            "  -0.99995465 -1.00001913 -0.99999187 -1.00000344 -0.99999854 -1.00000062\n",
            "  -0.99999974 -1.00000011 -0.99999995 -1.00000002 -0.99999999 -1.\n",
            "  -1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS7HyrTNFV5t"
      },
      "source": [
        "## Strict Diagonal Dominance\n",
        "This last method is fairly tempting, but it raises an important question that we have so far avoided.  How long does it take to find the eigenvalues of a matrix?  The point is this: We want to solve $A\\mathbf{x} = \\mathbf{b}$ with a method that is faster than $\\mathcal{O}(N^3)$.  We don't know exactly how many steps the Jacobi method will require, but each step only takes $\\mathcal{O}(N)$ flops (well, technically it takes $\\mathcal{O}(N^2)$ flops still, because multiplying $T\\mathbf{x}_{k-1}$ is $\\mathcal{O}(N^2)$, but the point still applies), so there is hope that it will ultimately be faster than Gaussian elimination.  However, if we have to start our method with a call to `eig` then we should worry that `eig` might take so long that we might as well just use Gaussian elimination in the first place.  \n",
        "\n",
        "It turns out that our fears are well founded.  Most methods to find eigenvalues are iterative, so big-oh notation doesn't necessarily apply, but it is not uncommon for the `eig` function to take at least as long as Gaussian elimination.  This means that if we are forced to check the eigenvalues of $-P^{-1}T$ before we use a splitting method, we won't actually save any time over just using the `solve` function.  \n",
        "\n",
        "Fortunately, there are some other properties of our system that can tell us about the convergence of matrix splitting methods.  The most important such property is called *strict diagonal dominance*.  We say that a matrix is strictly diagonally dominant if the absolute value of each diagonal entry is greater than the sum of the absolute values of the other entries in that row.  That is, $A$ is strictly diagonally dominant if \n",
        "\n",
        "$|a_{ii}| > \\sum_{j \\neq i}|a_{ij}|$, \n",
        "\n",
        "for all $i\\leq N$.  (The summation notation means to add up every entry in the row except $|a_{ii}|$.)  This property is much easier to check than the eigenvalues of a matrix.  We will make use of the following theorem without proving it: \n",
        "\n",
        "The Jacobi method for solving $A\\mathbf{x} = \\mathbf{b}$ will converge if $A$ is strictly diagonally dominant.  \n",
        "\n",
        "There are a few things worth noting about this theorem.  First, this is a property of $A$, not of $M$.  You need to check if the original left hand side of your system is strictly diagonally dominant.  Second, this theorem says nothing about what happens when $A$ is not strictly diagonally dominant.  It is entirely possible to come up with such a system where the Jacobi method still converges.  If $A$ is not strictly diagonally dominant, then you still have to find the eigenvalues of $M$ to decide if the Jacobi method will converge.  Third, this theorem does not apply to all matrix splitting methods.  If you choose a different $P$ and $T$, there is no guarantee that the corresponding splitting method will converge.  \n",
        "\n",
        "This also explains why our original example converged.  In the first row, we had $|6| > |1| + |1|$.  In the second row, we had $|8| > |1| + |2|$.  In the third row, we had $|9| > |2| + |3|$.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX8t6T3aFV5t"
      },
      "source": [
        "# Gauss-Seidel Method\n",
        "Another type of system that is relatively easy to solve is a triangular system.  If we chose $P$ to be triangular, then we could solve systems of the form $P\\mathbf{x} = \\mathbf{c}$ in $\\mathcal{O}(N^2)$ flops, which is still much faster than Gaussian elimination.  We could therefore choose $P$ to be a triangular portion of the matrix $A$.  In particular, if we choose $P$ to be the main diagonal of $A$ and all the entries below it, then $P$ will be lower triangular.  We call the matrix splitting method with this choice of $P$ the *Gauss-Seidel method*.  For example, in our example system we would choose \n",
        "\n",
        "$P = \\left(\\begin{array}{c} 6 & 0 & 0 \\\\ 1 & 8 & 0 \\\\ 2 & 3 & 9 \\end{array}\\right)$ and $T = \\left(\\begin{array}{c} 0 & 1 & 1 \\\\ 0 & 0 & 2 \\\\ 0 & 0 & 0 \\end{array}\\right)$.  \n",
        "\n",
        "There is a useful function in the numpy package for extracting the lower triangular portion of a matrix called `tril`.  We can make this splitting with the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Si9hyw9FV5t",
        "outputId": "771ce1ce-a3b8-4e17-952f-0237e2fc2f19"
      },
      "source": [
        "P = np.tril(A)\n",
        "print(P)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6 0 0]\n",
            " [1 8 0]\n",
            " [2 3 9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci0b4F4_FV5v",
        "outputId": "d87affdc-f4c1-44a2-ef5a-cc49554883ba"
      },
      "source": [
        "T = A - P\n",
        "print(T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 1]\n",
            " [0 0 2]\n",
            " [0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ics4GuUZFV5x"
      },
      "source": [
        "Besides the different choices of $P$ and $T$, the Gauss-Seidel method works exactly the same as the Jacobi method.  We can test that the Gauss-Seidel method will converge by checking the eigenvalues of $M = -P^{-1}T$.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3VxgSkoFV5x",
        "outputId": "60638d4b-c46a-4277-efb1-9568007c02aa"
      },
      "source": [
        "M = -scipy.linalg.solve(P, T)\n",
        "w, V = np.linalg.eig(M)\n",
        "print(np.max(np.abs(w)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09622504486493762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-koBFq4PFV5y"
      },
      "source": [
        "Since all of the eigenvalues are less than 1, this method will converge.  \n",
        "\n",
        "It turns out that the strict diagonal dominance test also works for the Gauss-Seidel method.  If $A$ (not $M$) is strictly diagonally dominant, then the Gauss-Seidel method will converge.  Again, this rule doesn't tell you what happens if $A$ is not strictly diagonally dominant.  It is entirely possible for one or both of the Jacobi and Gauss-Seidel methods to converge if $A$ is not strictly diagonally dominant.  \n",
        "\n",
        "To code the Gauss-Seidel method, we could use version 3 (or one of the working while loop versions) of the code from above with our new $P$ and $T$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxgUrbg9FV5y",
        "outputId": "50934a7e-c9eb-40d8-8db6-6a94d5d5bcf2"
      },
      "source": [
        "A = np.array([[6, 1, 1], [1, 8, 2], [2, 3, 9]])\n",
        "b = np.array([[10], [-8], [-8]])\n",
        "P = np.tril(A)\n",
        "T = A - P\n",
        "\n",
        "tolerance = 1e-8\n",
        "x0 = np.ones((3, 1))\n",
        "X = np.zeros((3, 101))\n",
        "X[:, 0:1] = x0\n",
        "\n",
        "for k in range(100):\n",
        "    X[:, (k+1):(k+2)] = scipy.linalg.solve_triangular(P, -T @ X[:, k:(k+1)] + b, lower=True)\n",
        "    if np.max(np.abs(X[:, k+1] - X[:, k])) < tolerance:\n",
        "        break\n",
        "X = X[:, :(k+2)]\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.          1.33333333  2.02160494  2.0090735   2.00101816  2.00005268\n",
            "   1.99999765  1.9999992   1.99999991  2.          2.        ]\n",
            " [ 1.         -1.41666667 -1.07445988 -1.0061389  -1.00013476 -0.99996125\n",
            "  -0.99999355 -0.99999949 -0.99999999 -1.         -1.        ]\n",
            " [ 1.         -0.71296296 -0.97998114 -0.99997003 -1.00018134 -1.00002462\n",
            "  -1.00000163 -0.99999999 -0.99999998 -1.         -1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP-cXixBFV5y"
      },
      "source": [
        "Notice that this method converged in fewer steps than the Jacobi method.  We already knew this would happen because the largest eigenvalue of $M$ for the Jacobi method was approximately $0.4236$, while the largest eigenvalue of $M$ for the Gauss-Seidel method was approximately $0.0962$.  The smaller the eigenvalue, the faster the splitting method, so we would expect Gauss-Seidel to converge faster for this problem.  This is actually fairly common.  As a rule of thumb, if both the Gauss-Seidel and the Jacobi method converge for a given problem, then Gauss-Seidel will typically be about twice as fast.  However, it is possible to find methods where one converges and the other does not or where both converge but the Jacobi method is faster.  In general, if you want to find the fastest method there is no substitute for checking the maximum eigenvalue of $M$.  "
      ]
    }
  ]
}